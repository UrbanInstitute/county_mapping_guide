---
title: "Mapping Guide"
author: "Vincent Pancini and Aaron R. Williams"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1: Getting Started with R and RStudio {.tabset}
## Brief
### R and RStudio 
* R is a free, open-source software for statistical computing and data science. You can download R [here](https://cran.r-project.org/).

* RStudio is a free, open-source integrated development environment (IDE) that runs on top of R. R users almost exclusively open RStudio and rarely directly open R. You can download RStudio [here](https://www.rstudio.com/products/rstudio/download/).

### RStudio Projects
* Creating an RStudio project for each data analysis project allows you to keep all files associated with that project together, and serves as an easy way to tell R where to load/save files.

## Extended
### R and RStudio
* Read more about R and RStudio below:
    + [R dor Data Science](https://r4ds.had.co.nz/)
    + [Urban Institute Intro to R](https://urbaninstitute.github.io/r-at-urban/intro-to-r.html#Introduction)
    
### RStudio Projects
* The command for setting working directories in R is `setwd()`, and the command for checking what the current working directory is `getwd()`. However, `setwd()` relies on absolute file paths. An absolute file path is a string that contains the root element and the complete directory list to locate a file. This can cause problems with loading and saving your files if that path ever changes, such as when reorganizing directories on your machine or when collaborating with people using different machines. RStudio projects make all file paths relative to the root directory, specified by a file with the extension .Rproj. 

* Read more about RStudio Projects and .Rproj files below:
    + [R for Data Science Chapter 8](https://r4ds.had.co.nz/workflow-projects.html)
    + [Using RStudio Projects from RStudio Support](https://support.rstudio.com/hc/en-us/articles/200526207-Using-RStudio-Projects)
    + [RStudio Projects and Working Directories: A Beginner's Guide](https://www.r-bloggers.com/2020/01/rstudio-projects-and-working-directories-a-beginners-guide/)

### Why map with R?
R can have a steeper learning curve than point-and-click tools, such as QGIS or ArcGIS, for geospatial analysis and mapping. However, creating maps in R has many advantages including:

1. Reproducibility: By creating maps with R code, you can easily share the outputs and the code that generated the output with collaborators, allowing them to replicate your work and catch errors easily.

2. Iteration: With point and click software like ArcGIS, making 50 maps would be 50 times the work/time. But using R, we can easily make make many iterations of the same map with a few changes to the code.

3. Easy Updates: Writing code provides a roadmap for others (and future you!) to quickly update parts of the map as needed. Say for example a collaborator wanted to change the legend colors of 50 state maps. With R, this is possible in just a few seconds!

4. An Expansive ecosystem: There are several R packages that make it very easy to get spatial data, create static and interactive maps, and perform spatial analyses. This feature rich package ecosystem which all play nice together is frankly unmatched by other programming languages and even point and click tools like QGIS and ArcGIS. Some of these R packages include:
  
5. Cost: Most point-and-click tools for geospatial analysis are proprietary and expensive. R is free open-source software. The software and most of its packages can be used for free by anyone for almost any use case.

* Read more about mapping with R below:
    + [Urban Institute Mapping in R](https://urbaninstitute.github.io/r-at-urban/mapping.html#Helpful_Learning_Resources)


# Section 2: Geospatial Data {.tabset}
## Brief
### Spatial Concepts
Creating a map requires transforming the earth from its spherical shape (3D) to a planar shape (2D). A **coordinate reference system (CRS)** defines how the two-dimensional projected map relates to real places on the three-dimensional earth. When using multiple different geospatial datasets for mapping, they should have the same CRS prior to mapping. 

We recommend using the State Plane Coordinate System (SPCS), which is only used in the United States, for mapping at the county-level. 

We recommend using the `suggest_crs` function from the `crsuggest` package which helps spatial analysts determine an appropriate CRS for their data. 

## Extended
### Spatial Concepts
* Geographic coordinate reference systems: data with a three-dimensional representation of the Earth (i.e., the data have not been projected from what we think of as a globe to what we think of as a map). Data are typically stored as longitude and latitude.
  
  * Projection: A mathematical transformation that converts three-dimensional coordinates for a spheroid/ellipsoid into a two-dimensions.
  
  * Projected coordinate reference system: data with a two-dimensional representation of the Earth. A projected CRS is the combination of a geographic CRS and a projection. Data are typically stored in feet or meters, which is useful for distance-based spatial operations like calculating distances and creating buffers.

* Read more about coordinate reference systems [here](https://docs.qgis.org/3.16/en/docs/gentle_gis_introduction/coordinate_reference_systems.html).
* Read more about the State Plane Coordinate System [here](https://www.usgs.gov/faqs/what-state-plane-coordinate-system-can-gps-provide-coordinates-these-values#:~:text=The%20State%20Plane%20Coordinate%20System%20(SPCS)%2C%20which%20is%20only,the%20state's%20size%20and%20shape.).
* Read more about the `crsuggest` package [here](https://github.com/walkerke/crsuggest).

### Types of Geospatial Data
  * points: zero-dimensional geospatial objects that are often a single longitude and latitude.

  * lines: one-dimensional geospatial objects that are often a sequence of longitudes and latitudes.

  * polygons: two-dimensional geospatial objects that are a often a sequence of longitudes and latitudes outlining a shape

### Spatial data formats
  * .csv - geographic information is often stored in .csv files, especially for point data where it is sensible to have longitude and latitude columns.
  * .geojson - an open source file type for storing geospatial data in plain text.
  * Shapefiles (.shp) - a proprietary file format created by ESRI, the company that creates ArcGIS. A shapefile is actually three or more binary files.

### Types of Projections
  * Mercator projection
  * Alber's Equal Area projection
  * State Plane Coordinate Systems (SPCS)
  * EPSG Codes

### Geographies
Maps can be made with various geographic units. Some of these geographies include:

  * County - as of 2020, there are 3,143 counties and county equivalents in the 50 states and the District of Columbia. County equivalents include parishes and boroughs in Louisiana and Alaska respectively. 
  
  * ZIP Code Tabulation Areas (ZCTAs) - generalized areal representations of United States Postal Service (USPS) ZIP Code service areas. There are approximately 32,000 ZCTAs in the United States.
  
  * Public Use Microdata Areas (PUMAs) - non-overlapping, statistical geographic areas that partition each state or equivalent entity into geographic areas containing no fewer than 100,000 people each. As of 2012, there are 2,378 PUMAs in the United States. 


# Section 3: Using Geospatial Data in R {.tabset}
## Brief
### API and API Keys
* An **application programming interface (API)** is a connection between computers or between computer programs that allows two applications to talk to each other. An API allows applications to access data and interact with external software components.

* An **application programming interface (API) key** is a unique code used to identify and authenticate an application or user. API keys are often used to track and control how the API is being used.  

* The Census Data API gives the public access to raw statistical data from various Census Bureau data programs. It is an efficient way to query data directly from Census Bureau servers. You can request a Census API Key [here](https://api.census.gov/data/key_signup.html).

### Loading spatial data
  * `library(ggplot2)` - part of the `tidyverse` ecosystem, `ggplot2` is a package for creating data visualizations including maps. 
  * `library(sf)` - plots simple features (sf), which is a standardized way to encode spatial vector data. This function automatically references the geometry column and makes it simple to combine point, line, and polygon data.
  * `library(tigris)` - downloads and provides TIGER/Line shapefiles from the US Census Bureau. TIGER stands for Topologically Integrated Geographic Encoding and Referencing.
  * `library(tidycensus)` - can return simple feature geometry for geographic units along with variables from the decennial US Census or American Community survey. By setting geometry = TRUE in a tidycensus function call, tidycensus will use the tigris package to retrieve the corresponding geographic dataset from the US Census Bureau and pre-merge it with the tabular data obtained from the Census API.
  * `library(crsuggest)` - attempts to match an input spatial dataset with corresponding coordinate reference systems that will work well for mapping and/or spatial analysis

## Extended
### API and API Keys
* Read more about API's and API keys [here](https://whatis.techtarget.com/definition/API-key). 
* Read more about the Census Data API [here](https://www.census.gov/data/developers/guidance/api-user-guide.Overview.html).


# Section 4: Examples

## Example 1 - Tract using tidycensus
```{r message = FALSE, warning = FALSE}
# install.packages(c("tidyverse", "tidycensus", "crsuggest", "sf"))
library(tidyverse)
library(tidycensus)
library(crsuggest)
library(sf)
census_api_key("75ed382ac6c6e5650cbc1801e618f88484e24642")

# Retrieve data
tc_tracts <- tidycensus::get_acs(geography = "tract",
                                 variables = c(medincome = "B19013_001"),
                                 state = 51,
                                 county = 059,
                                 year = 2019,
                                 geometry = TRUE,
                                 progress_bar = FALSE)

# Figure out best projection for data
possible_crs <- crsuggest::suggest_crs(tc_tracts)

# Transform data to match best projection
tc_tracts_proj <- sf::st_transform(tc_tracts, crs = 6488)

# Create map
tract_tidycensus <- ggplot() +
  geom_sf(data = tc_tracts_proj,
          aes(fill = estimate)) +
  scale_fill_gradient(high = "#132B43", low = "#56B1F7",
                      labels = scales::dollar) +
  labs(title = "Median income income in Fairfax County, VA by census tract ",
       fill = "Median Income") +
  theme_void()

ggsave("tract_tidycensus.png", plot = tract_tidycensus, width = 8, height = 5, units = "in")
```

## Example 2 - ZCTA using tidycensus
```{r message = FALSE, warning = FALSE}
# install.packages(c("tidyverse", "tidycensus", "crsuggest", "sf"))
# library(tidyverse)
# library(tidycensus)
# library(crsuggest)
# library(sf)
# census_api_key("75ed382ac6c6e5650cbc1801e618f88484e24642")

# Retrieve data
tc_zcta <- tidycensus::get_acs(geography = "zcta",
                               variables = c(medincome = "B19013_001"),
                               state = 51,
                               year = 2019,
                               geometry = TRUE,
                               progress_bar = FALSE)

# Figure out best projection for data
possible_crs <- crsuggest::suggest_crs(tc_zcta)

# Transform data to match best projection
tc_zcta_proj <- sf::st_transform(tc_zcta, crs = 6591)

# Create map
zcta_tidycensus <- ggplot() +
  geom_sf(data = tc_zcta_proj,
          aes(fill = estimate)) +
  scale_fill_gradient(high = "#132B43", low = "#56B1F7",
                      labels = scales::dollar) +
  labs(title = "Median income in Fairfax County, VA by ZCTA",
       fill = "Median Income") +
  theme_void()

ggsave("zcta_tidycensus.png", plot = zcta_tidycensus, width = 8, height = 5, units = "in")
```

## Example 3 - PUMA using tidycensus
```{r message = FALSE, warning = FALSE}
# install.packages(c("tidyverse", "tidycensus", "crsuggest", "sf"))
# library(tidyverse)
# library(tidycensus)
# library(crsuggest)
# library(sf)
# census_api_key("75ed382ac6c6e5650cbc1801e618f88484e24642")

# Retrieve data
tc_puma <- tidycensus::get_acs(geography = "public use microdata area",
                               variables = c(medincome = "B19013_001"),
                               state = 51,
                               year = 2019,
                               geometry = TRUE,
                               progress_bar = FALSE)

# Figure out best projection for data
possible_crs <- crsuggest::suggest_crs(tc_puma)

# Transform data to match best projection
tc_puma_proj <- sf::st_transform(tc_puma, crs = 6591)

# Create map
puma_tidycensus <- ggplot() +
  geom_sf(data = tc_puma_proj,
          aes(fill = estimate)) +
  scale_fill_gradient(high = "#132B43", low = "#56B1F7",
                      labels = scales::dollar) +
  labs(title = "Median income in Fairfax County, VA by PUMA",
       fill = "Median Income") +
  theme_void()

ggsave("puma_tidycensus.png", plot = puma_tidycensus, width = 8, height = 5, units = "in")
```

## Example 4 - PUMA and loading in original data
```{r message = FALSE, warning = FALSE}
# install.packages(c("tidyverse", "tigris", "sf"))
#library(tidyverse)
library(tigris)
#library(sf)

# Pull the spatial data from (tigris)
pumas <- tigris::pumas(state = 39, year = 2019, cb = TRUE, progress_bar = FALSE) %>%
  rename(puma = PUMACE10) %>%
  transmute(puma = as.numeric(puma))
## the `year` argument defaults to 2020, but cartographic boundary PUMAs are not yet available for years after 2019, so use the argument `year = 2019` instead to request your data.
## TIGER/Line shapefiles are high-resolution and follow legal boundaries. Their larger size slows down processing time, and because they follow legal boundaries, some objects like bodies of water will not be visible. Cartographic boundary files are quicker to download and follow the US coastline, which better aligns with maps that we're used to looking at. The argument `cb = TRUE` pulls the cartographic boundary files, but setting the argument to `cb = FALSE` will pull the TIGER line files.

# Figure out best projection for data
possible_crs <- crsuggest::suggest_crs(pumas)

# Transform data to match best projection
pumas_proj <- sf::st_transform(pumas, crs = 6549)

# Load in original data
ss_inc <- read_csv(here::here("mean_ssinc_oh_2019.csv"))

# Join the puma shapefiles to our original puma-level data so we can map it
## `left_join()` returns all rows from the first argument `x` (in this case `pumas_proj`), and all columns from the first two arguments `x` and `y `(in this case, `pumas_proj` and `ss_inc` respectively). 
ss_inc_puma <- left_join(pumas_proj, ss_inc, by = "puma")

# We have data for the entire state, but we only want to map Franklin County.
# First get county shapefiles for the state of Ohio
ohio <- tigris::counties(state = 39, year = 2019, cb = TRUE, progress_bar = FALSE)

# Figure out best projection for data
possible_crs <- crsuggest::suggest_crs(ohio)

# Transform data to match best projection
ohio_proj <- sf::st_transform(ohio, crs = 6549)

# Now we can join the pumas to counties, and then filter to the county we're interested in
my_data <- sf::st_join(ss_inc_puma, ohio_proj, join = st_intersects) %>%
  filter(COUNTYFP == "049")

# And finally, we can create a map
puma_own_data <- ggplot() +
  geom_sf(data = my_data,
          aes(fill = mean_ssinc),
          color = "black",
          size = 0.2) +
  scale_fill_gradient(high = "#132B43", low = "#56B1F7",
                      labels = scales::dollar,
                      #trans = 'reverse'
  ) +
  labs(title = "Mean Social Security Income in Franklin County, OH, by PUMA",
       fill = "Mean SSI") +
  theme_void()

ggplot2::ggsave("puma_own_data.png", plot = puma_own_data, width = 8, height = 8, units = "in")
```


# Bibliography and References
